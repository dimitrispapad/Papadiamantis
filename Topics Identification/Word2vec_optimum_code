import re
import chardet
import spacy
import numpy as np
import hdbscan
import pandas as pd
import matplotlib.pyplot as plt
from gensim.models import Word2Vec
from collections import defaultdict
from scipy.spatial.distance import cosine
from sklearn.manifold import TSNE

# Load and preprocess text
with open("Diigimata.txt", 'rb') as file:
    encoding = chardet.detect(file.read())['encoding']
with open("Diigimata.txt", 'r', encoding=encoding) as file:
    raw_text = file.read()

def preprocess_text(text):
    return re.sub(r'[^\w\s]', '', text.lower())

processed_text = preprocess_text(raw_text)

# Load Greek language model
nlp = spacy.load("el_core_news_sm")
nlp.max_length = 3_000_000

# Load stopwords
try:
    with open("stopwords.txt", 'r', encoding='utf-8') as f:
        stopwords = set(line.strip() for line in f)
except:
    stopwords = set()

# Tokenize
doc = nlp(processed_text)
tokenized_sentences = [
    [token.text for token in sent if not token.is_space and not token.is_punct and token.text not in stopwords]
    for sent in doc.sents
]

# Train Word2Vec with best t-SNE config
model = Word2Vec(
    sentences=tokenized_sentences,
    vector_size=200,
    window=3,
    min_count=1,
    epochs=30,
    sg=1,
    workers=4,
    seed=42,
    negative=10,
    sample=1e-4
)

# Extract and reduce word vectors
words = list(model.wv.index_to_key)[:8000]
vectors = np.array([model.wv[word] for word in words])

tsne = TSNE(n_components=2, random_state=42)
reduced = tsne.fit_transform(vectors)

# HDBSCAN clustering
clusterer = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=5, metric='euclidean')
labels = clusterer.fit_predict(reduced)

# Group words by cluster
cluster_words = defaultdict(list)
for word, label in zip(words, labels):
    if label != -1:
        cluster_words[label].append(word)

# Find 10 representative words per cluster
top_words = {}
for label, words_in_cluster in cluster_words.items():
    vecs = np.array([model.wv[word] for word in words_in_cluster])
    center = vecs.mean(axis=0)
    dists = [(word, np.linalg.norm(model.wv[word] - center)) for word in words_in_cluster]
    top_words[label] = [w for w, _ in sorted(dists, key=lambda x: x[1])[:10]]

# Save cluster words to CSV
df_top_words = pd.DataFrame.from_dict(top_words, orient='index').T
df_top_words.to_csv("tsne_word2vec_top_words_per_cluster20.csv", index=False)
print("âœ… Saved cluster top words to tsne_word2vec_top_words_per_cluster.csv")

# Plot clusters
plt.figure(figsize=(12, 8))
for label in set(labels):
    if label == -1:
        continue
    idx = np.where(labels == label)
    plt.scatter(reduced[idx, 0], reduced[idx, 1], label=f"Cluster {label}", alpha=0.6)

plt.title("t-SNE Word Clusters (Word2Vec)")
plt.xlabel("Component 1")
plt.ylabel("Component 2")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True)
plt.tight_layout()
plt.savefig("tsne_word2vec_word_clusters_best.png")
plt.show()
